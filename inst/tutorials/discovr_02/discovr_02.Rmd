---
title: "discovr: Summarizing data"
author: "Andy Field"
output:
  learnr::tutorial:
    progressive: false
    theme: "paper"
runtime: shiny_prerendered
description: "Summarizing data (frequency distributions, grouped frequency distributions, relative frequencies, histograms, mean, median, variance, standard deviation, interquartile range)"
bibliography: discovr_02.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(learnr)
library(tidyverse)

hint_text <- function(text, text_color = "#E69F00"){
  hint <- paste("<font color='", text_color, "'>", text, "</font>", sep = "")
  return(hint)
}

#Read dat files needed for the tutorial

ice_tib <- discovr::ice_bucket

```


# discovr: Summarizing data

## Overview

This tutorial is one of a series that accompanies [Discovering Statistics Using R and RStudio](https://www.discoveringstatistics.com/books/discovering-statistics-using-r/) [@fieldDiscoveringStatisticsUsing2020] by me, [Andy Field](https://en.wikipedia.org/wiki/Andy_Field_(academic)). These tutorials contain abridged sections from the book so there are some copyright considerations but I offer them under a [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](http://creativecommons.org/licenses/by-nc-nd/4.0/), ^[Basically you can use this tutorial for teaching and non-profit activities but do not meddle with it or claim it as your own work.]

* Who is the tutorial aimed at?
    - Anyone teaching from or reading [Discovering Statistics Using R and RStudio](https://www.discoveringstatistics.com/books/discovering-statistics-using-r/)  may find them useful.
* What is covered?
    - This tutorial looks at some key concepts in using **R** and **RStudio**. It would be a useful tutorial to run at the start of a module, or alongside teaching based on Chapter 1 of [Discovering Statistics Using R and RStudio](https://www.discoveringstatistics.com/books/discovering-statistics-using-r/).
    - This tutorial *does not* teach the background theory: it is assumed you have either attended my lecture or read the relevant chapter in the aforementioned book (or someone else's)

If you haven't done so already, I recommend working through [this tutorial](http://milton-the-cat.rocks/learnr/r/r_getting_started/) on how to install, set up and work within R and RStudio before starting this tutorial.

## Packages and data

The tutorials are self-contained (you practice code in code boxes) so you don’t need to use RStudio at the same time. However, I recommend that you open another RStudio session to the one that you're using to run this tutorial. In this second RStudio session, open an R markdown file and practice everything you do in the tutorial in the R markdown file (and save it). This video explains the sort of workflow that I mean:

![]("https://youtu.be/FE0ntX0dyc4")

`r hint_text("Within the tutorial itself, everything will work. To replicate things outside of the tutorial you will need to load the relevant packages and data.")`

### Packages

To work *outside of this tutorial* you need to load the following packages:

* `here` [@here]
* `tidyverse` [@tidyverse]

If you haven't already done this, install a package at the command line using `install.packages("package_name")`, where *package_name* is the name of the package. If the package has already been installed, load it by typing `library(package_name)`, where *package_name* is the name of the package, within the first code chunk in your R markdown file.

### Data

To work *outside of this tutorial* you need to download the following data file:

* [ice_bucket.csv](http://www.discoveringstatistics.com/repository/discovr_data/ice_bucket.csv)

Assuming you set up an RStudio project in the way that [I recommend in this tutorial](http://milton-the-cat.rocks/learnr/r/r_getting_started/#section-working-in-rstudio), then save the data files to the folder within your project folder called `data`. Then, in the first code chunk in your R Markdown document, execute:

```{r, eval=FALSE}
ice_tib <- here::here("data/ice_bucket.csv") %>% readr::read_csv()
```


## Frequency distributions

We will use data about memes, which typically have a common pattern: they start small, rapidly expand in popularity and then die out. Specifiaclly we'll use data from the ice bucket challenge. You can check Wikipedia for the full story, but it all started (arguably) with golfer Chris Kennedy tipping a bucket of iced water on his head to raise awareness of the disease amyotrophic lateral sclerosis (ALS, also known as Lou Gehrig's disease).  The idea is that you are challenged and have 24 hours to post a video of you having a bucket of iced water poured over your head. In this video you also challenge at least three other people. If you fail to complete the challenge your forfeit is to donate to charity (in this case ALS). Many people completed the challenge and made donations.

The ice bucket challenge generated something like 2.3 million on YouTube. The data are stored in `ice_tib`, which contains one variable `upload_day` that is the number of days after Chris Kennedy’s initial challenge that each of 2,323,452 ice bucket related videos were uploaded to YouTube. For example, if the value is 21 it means that the video was uploaded 21 days after Chris Kennedy’s initial challenge. We can't see the pattern of the data easily from 2,323,452 scores. However, we can if we count the frequency of each score and place it in a table.

### Frequency tables

To get a basic frequency table we use the `group_by()` and `summarise()` and `n()` functions from the `dplyr` package (automatically loaded as part of tidyverse). These functions do the following:

* `group_by()`: groups the data by whatever variable (or variables) you name within the function.
* `summarise()`: creates a summary table based on whatever variables you create within the function
* `n()`: counts the number of scores

We can combine these functions to create a frequency table called `freq_tbl` as follows:

```{r, eval=FALSE}
freq_tbl <- ice_tib %>%
  dplyr::group_by(upload_day) %>% 
  dplyr::summarise(
    frequency = n()
  )
```

To count the frequencies of scores we need to do two things:

1. Tell R to treat values that are the same, as being in the same group or category. For example, tell it that scores of 21 are from the same group/category. We do this using `group_by(upload_day)`, which tells R to treat scores that are the same within `upload_day` as being in the same group. Any subsequent operation will be conducted on these 'groups'. 
2. Count how many scores fall into each 'category'. This is done using `summarize()`, within which we create a variable called `frequency` that counts how many items are in each group created by `group_by()`. This variable will, therefore, contain the number of times each value of `upload_day` occurs.

To sum up, the code feeds the data stored in `ice_tib` into the `group_by()` function and asks it to group the output by the variable `upload_day`. Having done this, a variable called `frequency` is created that counts how many scores is in each 'group'. Try this code in the box below.

`r hint_text("TIP: remember to also execute")` `freq_tbl` `r hint_text("to see the table")`

```{r freq_dist, exercise=TRUE, exercise.lines=6}


```

```{r freq_dist-solution}
freq_tbl <- ice_tib %>%
  dplyr::group_by(upload_day) %>% 
  dplyr::summarise(
    frequency = n()
  )
freq_tbl
```

We can see, for example, that 29000 videos were uploaded 30 days after Chris Kennedy’s initial challenge, and 10000 were uploaded 27 days after.

### Grouped frequency tables

However, the frequency table that we just produced is large and a little unweildy. It might be useful to instead have a table that counts the frequencies for a range of scores. For example, how many videos were uploaded between 21 and 24 days, and 25 and 28 days. This is known as a *grouped* frequency distribution. To produce one of these, first we have to place the values of `upload_days` into what are known as *bins*. The values of the number of days range from 21 to 76 days after Chris Kennedy’s initial challenge. Imagine we wanted to group the data in such a way as to see how many videos were uploaded every 4 days (instead of every day). To do this, we'd need to group the values of days into bins of 21-24, 25-28, 29-32 and so on. Notivce that each 'bin' is made up of 4 days worth of values. We can create these bins using `ggplot2::cut_width()` which takes this form:

```{r, eval=FALSE}
ggplot2::cut_width(variable, width_of_bin)
```


In which we place the variable that we wish to spread across bins, and `width_of_bin` is how wide we want the bins to be. If we want to split the variable `upload_day` into bins containing 4 days worth of data we'd use:

```{r, eval=FALSE}
ggplot2::cut_width(upload_day, 4)
```

Combining this with `dplyr::mutate()` (which we encountered in the **discovr_01** tutorial). To create a new variable called `days_group`, we could execute:

```{r, eval=FALSE}
gp_freq_tbl <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) 
```

This creates a new object called `gp_freq_tbl` that contains `ice_tib` biut with an extra column/variable called `days_group` that indicates into which 'bin' the value of `upload_day` falls.

Try the above code in the box:

`r hint_text("TIP: remember to also execute")` `gp_freq_tblt` `r hint_text("to see the table")`


```{r cut_width, exercise=TRUE, exercise.lines=5}


```

```{r cut_width-solution}
gp_freq_tbl <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    )
gp_freq_tbl
```

Notice that each value of `upload_days` now has a corresponding value of `days_group` containing the 'bin' to which the score has been assigned. For example, the first score of 34 has been assigned to the bin labelled `(30, 34]`. This is the bin containing any score above 30 up to and including 34. (The label uses standard mathematical notation for sets where `(` or `)` means 'not including' and `[` or `]` means 'including').

Having done this we can again use `summarize()` and `n()` to count the scores as we did before except that this time we group by `days_group` instead of `upload_day`. The full code to create a grouped frequency table called `gp_freq_tbl` would be:

```{r, eval=FALSE}
gp_freq_tbl <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) %>% 
  dplyr::group_by(days_group) %>% 
  dplyr::summarise(
    frequency = n()
  )
```

Try this below.

`r hint_text("TIP: remember to also execute")` `gp_freq_tblt` `r hint_text("to see the table")`

```{r gp_freq_dist, exercise=TRUE, exercise.lines=10}


```

```{r gp_freq_dist-solution}
gp_freq_dist <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) %>% 
  dplyr::group_by(days_group) %>% 
  dplyr::summarise(
    frequency = n()
  )
gp_freq_dist
```

We can see, for example that 534000 videos were uploaded after 38 days and up to and including 42 days. 

### Relative frequencies

We now have an object `gp_freq_dist` that contains the number of days grouped into bins of 4 days (`days_group`) and the number of videos uploaded during each of the time periods represented by those bins (`frequency`). If we want to calculate the relative frequency (i.e., the proportion of videos uploaded during each of the time periods represented by the bins) we can use `dplyr::mutate()` to add a variable that divides the frequency by the total number of videos uploaded. We can find this total using `sum()`.

```{r, eval = FALSE}
gp_freq_dist <- gp_freq_dist %>% 
  dplyr::mutate(
    relative_freq = frequency/sum(frequency)
  )
```

Within this code we pipe the object `gp_freq_dist` that we previously created into the `mutate()` function. Within that we create a new column called `relative_freq` using `frequency/sum(frequency)`. The effect of this command is that for each value of the variable `frequency` within `gp_freq_dist`, a new value is computed that is the original value divided by the sum (or total) of all of the frequencies. This process converts the raw frequancy into a relative frequency. Try this code in the box below.


```{r rel_freq-setup}
gp_freq_dist <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) %>% 
  dplyr::group_by(days_group) %>% 
  dplyr::summarise(
    frequency = n()
  )
```


```{r rel_freq, exercise=TRUE, exercise.lines=5}


```

```{r rel_freq-solution}
gp_freq_dist <- gp_freq_dist %>% 
  dplyr::mutate(
    relative_freq = frequency/sum(frequency)
  )
gp_freq_dist
```


### Efficient code

In the tasks above we created the table of relative frequencies step by step:

1. We created `gp_freq_dist` from `ice_tib` and added the variable `days_group` to it.
2. We fed `gp_freq_dist` into a pipe that grouped by `days_group` and then calculated the frequency. We saved it using the same name (`gp_freq_dist`).
3. We fed `gp_freq_dist` into a pipe that added a column with the relative frequency.

Usually it's more efficient to carry out these steps in one piece of code. For example, if we combine all of the previous operations we get:

```{r eval=FALSE}
gp_freq_dist <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) %>% 
  dplyr::group_by(days_group) %>% 
  dplyr::summarise(
    frequency = n()
  ) %>% 
  dplyr::mutate(
    relative_freq = frequency/sum(frequency),
    percent = relative_freq*100
  )
  
gp_freq_dist
```


This code takes the data in `ice_tib`, feeds it into `mutate()` to create a new variable called `days_group` which contains the 'bin' to which the score in `upload_day` belongs. Having added these 'variable'bins', we group the data by them using  `group_by()`, count how many scores fall into each bin using `summarize` and store these in a variable called `frequency`. We then feed this summary table into `mutate()` to create new variables containing the relative frequency in its raw form and expressed as a percentage. We store the summary table in an object called `gp_freq_dist`. Try this code in the box:


```{r rel_freq_eff, exercise=TRUE, exercise.lines=13}


```

```{r rel_freq_eff-solution}
gp_freq_dist <- ice_tib %>% 
  dplyr::mutate(
    days_group = ggplot2::cut_width(upload_day, 4)
    ) %>% 
  dplyr::group_by(days_group) %>% 
  dplyr::summarise(
    frequency = n()
  ) %>% 
  dplyr::mutate(
    relative_freq = frequency/sum(frequency),
    percent = relative_freq*100
  )
  
gp_freq_dist
```

## Histograms

As well as tabulated frequency distributions, we can visualise distributions using histograms. `ggplot2` is a powerful package for producing data visualisations that we will explore in detail in the **discovr_05** tutorial. For now, we will use it to create a histogram without worrying about how it works.

### A basic histogram using `ggplot2`

Let's start by plotting a histogram of number of days between the original ice bucket challenge video and when subsequent videos were uploaded. Remember, the data are stored in a variable called `upload_day` in the `ice_tib` tibble. To initiate the plot we use the `ggplot()` function, which at its simplest has this general form:

`ggplot2::ggplot(my_tib, aes(variable_for_x_axis, variable_for_y_axis))`

Within the `ggplot()` function replace `my_tib` with the name of the tibble containing the data you want to plot, and within the `aes()` function replace `variable_for_x_axis` with the name of the variable to be plotted on the *x*-axis (horizontal), and replace `variable_for_y_axis` with the name of the variable to be plotted on the *y*-axis (vertical). To plot the days since the first ice bucket challenge video that each video was uploaded, we could execute:

`ggplot2::ggplot(ice_tib, aes(upload_day))`

This command uses the tibble called *ice_tib*, and plots the variable **upload_day** on the *x* axis (for a histogram we don't need to specify *y*). This command tells `ggplot2` *what* to plot, but not *how* to plot it. We need to add something called a **geom** to display the data. For a histogram we use `geom_histogram()`:

```{r, eval = FALSE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram()
```

This command tells **R** to take the object created by `ggplot2::ggplot(ice_tib, aes(upload_day))` and add (`+`) a layer to it using `geom_histogram()`. Try this code in the box below.


```{r ice_hist, exercise=TRUE}

```

```{r ice_hist-solution}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram()
```


By default `ggplot2` constructs the bins of the histogram to be 1/30th the width of the data. You can over-ride this default by specifying `binwidth = ` within the `geom_histogram()` function. In the code box above, type `binwidth = 1` into the brackets after `geom_histogram` and execute the code. Note how the histogram changes. Feel free to try other binwidths, but 1 makes sense for these values because responses could only be whole numbers.

### Changing the colours of the bars

We can change the colour of the bars by including `fill = ` within the `geom_histogram()` function. For example, we could specify the colour red as:

`geom_histogram(binwidth = 1, fill = "red")`

Try this in the code box below and run the code.

`r hint_text("TIP: Note that options within a function are separated by a comma. In this example, ")` `binwidth = 1, fill = "red"` `r hint_text("will work but ")` `binwidth = 1 fill = "red"` `r hint_text("(note the comma is missing) would throw an error.")`

```{r ice_hist_fill, exercise=TRUE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1)
```

You can also specify any [Hex colour code](http://www.color-hex.com/). For example, the shade of blue defined by hex code "#56B4E9" is good for colour blind people, so we could specify this:

`geom_histogram(binwidth = 1, fill = "#56B4E9")`

Try this below by replacing `"red"` with `"#56B4E9"` and running the code. Play around with other hex codes.

```{r ice_hist_hex, exercise=TRUE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "red")
```

```{r ice_hist_hex-solution}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9")
```

You can also make filled objects semi-transparent by using `alpha = ` where alpha is a proportion (i.e., between 0 and 1). For example, if you want the histograms to have 20% opacity you could include  `alpha = 0.2` in the `geom_histogram()` function (remembering to separate it from other options with a comma). In the code box below try setting 50% opacity by editing the geom to be:

`geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5)`

Try out some other values of alpha.

`r hint_text("Tip: Remember that values of alpha must fall between 0 and 1")`

```{r ice_hist_alpha, exercise=TRUE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "red")
```

```{r ice_hist_alpha-solution}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5)
```

### Editing axis labels

To change the labels on the *x*- and *y*-axis we can use the `labs()` function. To do this, we add a `+` after the `geom_histogram()` function and on the next line type:

`labs(y = "label_for_y_axis", x = "label_for_x_axis")`

Replacing `label_for_y_axis` with the text we want on the *y*-axis and `label_for_x_axis` with the text that we want on the *x*-axis. For the current plot, we are plotting the frequency of uploads (because it's a histogram) on the *y*-axis and the number of days since the original ice bucket challenge on the *x*-axis, so we might use:

`labs(y = "Frequency", x = "Days since first ice bucket challenge video")`

Try running the code in the box below, then adding the line above and running it again. You should see that the axis labels change.

```{r ice_hist_labs, exercise = TRUE, exercise.lines=3}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5)
```

```{r ice_hist_labs-solution}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5) +
  labs(y = "Frequency", x = "Days since first ice bucket challenge video")
```

### Changing theme

`ggplot2` has various built in themes that change the appearance of the plot. The two we will use most often are `theme_bw()`, which applies a black and white theme and `theme_minimal()` which applies a minimalist theme. Both of thes ethemes are good for scientific plots (like the ones you'll find in journal artciles). To apply a theme we add `+` after the previous function and then type `theme_bw()` or `theme_minimal()`. For example, our histogram code so far is:

```{r, eval = FALSE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5) +
  labs(y = "Frequency", x = "Days since first ice bucket challenge video")
```

To apply a minimalist theme, the code would be:

```{r, eval = FALSE}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5) +
  labs(y = "Frequency", x = "Days since first ice bucket challenge video") +
  theme_minimal()
```

Notice that I added `+` after the `labs()` function and then included the function for the theme I wanted to apply.

Run the code below to view the histogram so far. Then add the code to apply `theme_minimal()` like I have above, re-run the code and notice the theme change:

```{r ice_hist_theme, exercise=TRUE, exercise.lines=4}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5) +
  labs(y = "Frequency", x = "Days since first ice bucket challenge video")
```

```{r ice_hist_theme-solution}
ggplot2::ggplot(ice_tib, aes(upload_day)) +
  geom_histogram(binwidth = 1, fill = "#56B4E9", alpha = 0.5) +
  labs(y = "Frequency", x = "Days since first ice bucket challenge video") +
  theme_minimal()
```

Now try changing `theme_minimal()` to `theme_bw()`, `theme_classic()` and `theme_dark()` to see what effect it has on the plot.

We'll return to the `ggplot2` package in more depth in **discovr_05**.

## Summarizing data

We've seen already that functions take the form of a command followed by brackets. We also saw that there are usually options that can be placed within those brackets (for example, in the previous section we changed the binwidth and bar colour of the histogram by placing instructions within the `geom_histogram()` function). We'll explore this idea more by looking at the functiosn to estimate the mean and median of the ice bucket scores

### The mean and median

We can compute the mean using the built-in function `mean()`. The full format of the function is:

```{r, eval=FALSE}
mean(variable, trim = 0, na.rm = FALSE)
```

Which just says that you need to include a reference to the data that you want the mean for, and that you can set two arguments:

* **trim**: allows you to trim the scores before calculating the mean by specifying a value between 0 and 0.5. The default is 0 (no trim), but if you wanted to trim 10% of scores from each end of the distribution you could set *trim = 0.1*, similarly to trim 20% from each end before computing the mean set *trim = 0.2*.
* **na.rm**: you'll see this in many functions, it stands for 'NA remove'. In **R** missing values are denoted as `NA` (not available), so by setting `na.rm = TRUE` (or `na.rm = T` for short) you ask **R** to remove missing values before computing the mean. The default is `na.rm = FALSE` so if the function ever throws an error it's probably because you have missing values and you have forgotten to set na.rm to true.

The function for the median has a similar format except that there isn't an argument to trim the data because that wouldn't make sense (the median is effectively the data with a 50% trim):

```{r, eval=FALSE}
median(variable, na.rm = FALSE)
```

If you are happy with the default settings you don't need to specify those arguments explicitly. For example, to find the mean of the variable `upload_day` from the `ice_tib` tibble, we could execute:

`r hint_text("TIP: Remember from the discovr_01 tutorial that ")` `ice_tib$upload_day` `r hint_text("is a way to select the variable ")` `upload_day` `r hint_text("from the ")` `ice_tib` `r hint_text("tibble")`

```{r, eval = FALSE}
mean(ice_tib$upload_day)
```

However, if we wanted to remove missing values we need to override the default setting for the 'na.rm` argument:

```{r, eval = FALSE}
mean(ice_tib$upload_day, na.rm = TRUE)
```

We can obtain the median in much the same way.

`r hint_text("TIP: To find the list of options available for a particular function remember that you can get help by executing ? and the name of the function (e.g., ?mean).")`

Use the code box below to obtain the mean and median number of days after the original ice bucket video that other videos were uploaded. 

```{r ice_mean, exercise = TRUE}

```

```{r ice_mean-solution}
mean(ice_tib$upload_day)
median(ice_tib$upload_day)
```


### Quantifying the 'fit' of the mean

We can use the functions `var()`, `sd()` to get the variance and standard deviation of the ice bucket scores. These functions behave exactly like `mean()` in that we input the variable for which we want the variance and standard deviation and specify how we treat missing values (by default they are not removed):

```{r, eval=FALSE}
var(variable_name, na.rm = FALSE)
sd(variable_name, na.rm = FALSE)
```

To get the variance and standard deviation of the days since the original ice bucket video that other videos were uploaded we'd execute:

```{r, eval=FALSE}
var(ice_tib$upload_day, na.rm = FALSE)
sd(ice_tib$upload_day, na.rm = FALSE)
```

`r hint_text("TIP: Because the current data has no missing scores we can omit the default argument of 'na.rm=FALSE'")`

Use the box below to calculate the variance and standard deviation of the `upload_day` variable.

```{r ice_var, exercise = TRUE}

```

```{r ice_var-solution}
var(ice_tib$upload_day)
sd(ice_tib$upload_day)
```

### The inter-quartile range

We can use the `IQR()` function to obtain the interquartile range of a set of scores. This function has an additional option of `type = ` which allows you to specify one of 8 different ways to calculate the IQR. The default is 7. There is an argument for using `type  = 8`, which uses a method recommended by [@hyndman_sample_1996]. 

```{r, eval=FALSE}
IQR(variable_name, na.rm = FALSE, type = 7)
```

To get the inter-quartile range of the days since the original ice bucket video we'd execute:

```{r, eval=FALSE}
IQR(ice_tib$upload_day, type = 8)
```


In the code box below, use this function to get the inter-quartile range of the `upload_day` variable.

```{r ice_iqr, exercise = TRUE}

```

```{r ice_iqr-solution}
IQR(ice_tib$upload_day, type = 8)
```

### Rounding values

We can use the `round()` function to round off values. It 
```{r, eval=FALSE}
round(value, number_of_decimal_places = 0)
```

In which we input a `value`, and specify the number of decimal places we want (the default is 0, which returns a whole number). For example, to round the value 3.211420 to a whole number we would execute:
```{r, eval=FALSE}
round(3.211420)
```

But to round it to two decimal places we would include the number two after a comma:
```{r, eval=FALSE}
round(3.211420, 2)
```

We could also use a pipe to feed a mean, median or variance into the round function. For example, to round the value of the variance of `upload_day` to 3 decimal places we could execute:

```{r, eval=FALSE}
var(ice_tib$upload_day) %>%
  round(3)
```

Try rounding the variance, standard deviation and mean of `upload_day` to 2 decimal places in the box below:

```{r ice_rnd, exercise = TRUE}

```

```{r ice_rnd-solution}
# Variance
var(ice_tib$upload_day) %>% round(2)
# SD
sd(ice_tib$upload_day) %>% round(2)
# Mean
mean(ice_tib$upload_day) %>% round(2)
```

## Creating a summary table

### Using `summarize()` to compute multiple summary statistics

So far we have looked at computing individual statistics for a set of scores, but what if we want to combine these values into a table? We can do this using the `summarise()` function described earlier in the tutorial. The code looks like this:

```{r eval = FALSE}
ice_tib %>%
  dplyr::summarise(
    median =  median(upload_day),
    mean =  mean(upload_day),
    IQR = IQR(upload_day),
    variance = var(upload_day),
    std_dev = sd(upload_day)
    ) %>%
    round(., 2)
```

The code feeds the data stored in `ice_tib` into the `summarise()` function. In this function 5 new variables are created. The first we name `median` and it stores the output of `median(upload_day)`. In other words, we create a variable that we chose to call `median` (left hand side of the command) that stores the value of the median of the variable `upload_day` (right-hand side of the command). Similarly, we store the mean upload day in a variable called `mean`, the IQR in a variable called `IQR`, the variance in a variable called `variance` and the standard deviation in a variable called `std_dev`. All of these values are piped into the `round()` function which rounds them to two decimal places.

Try this in the code box:

```{r ice_sum, exercise = TRUE, exercise.lines=9}

```

```{r ice_sum-solution}
ice_tib %>%
  dplyr::summarise(
    median =  median(upload_day),
    mean =  mean(upload_day),
    IQR = IQR(upload_day),
    variance = var(upload_day),
    std_dev = sd(upload_day)
    ) %>%
    round(., 2)
```


### Storing summaries

If we want to store this table of summary statistics we can do so by assigning it to a new object. Let's say we want to assign it to an object called `upload_summary` then we'd add `upload_summary <-` to the beginning of the command:

```{r eval = FALSE}
upload_summary <- ice_tib %>%
  dplyr::summarise(
    median =  median(upload_day),
    mean =  mean(upload_day),
    IQR = IQR(upload_day),
    variance = var(upload_day),
    std_dev = sd(upload_day)
    ) %>%
    round(., 2) 
```

## Other resources

### Statistics

* The tutorials typically follow examples described in detail in @fieldDiscoveringStatisticsUsing2020, so that book is an obvious place to go for further reading.
* If any of the statistical content doesn't make sense, you could try my more introductory book *An adventure in statistics* [@fieldAdventureStatisticsReality2016].
* There are free lectures and screencasts on my [YouTube channel](https://www.youtube.com/user/ProfAndyField/)
* There are free statistical resources on my website [www.discoveringstatistics.com](http://www.discoveringstatistics.com)

### R

* [R for data science](http://r4ds.had.co.nz/index.html) by @wickhamDataScience2017 is an open-access book by the creator of the tidyverse (Hadley Wickham). It covers the *tidyverse* and data management.
* [ModernDive](http://moderndive.com/index.html) is an open-access textbook on **R** and **RStudio**
* [RStudio cheat sheets](https://www.rstudio.com/resources/cheatsheets/)
* [RStudio list of online resources](https://www.rstudio.com/online-learning/)
* [SwirlStats](http://swirlstats.com/students.html) is a package for *R* that launches a bunch of interactive tutorials.

## References


